{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://github.com/ml4a/ml4a-guides/blob/master/notebooks/recurrent_neural_networks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#if using Theano with GPU\n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on these ideas, let us create a generate function\n",
    "def generate(temperature=0.35, seed=None, num_chars=100):\n",
    "    predict_more=lambda x: len(x) < num_chars\n",
    "    \n",
    "    if seed is not None and len(seed) < max_len:\n",
    "        raise Exception('Seed text must be at least {} chars long'.format(max_len))\n",
    "\n",
    "    # if no seed text is specified, randomly select a chunk of text\n",
    "    else:\n",
    "        start_idx = random.randint(0, len(text) - max_len - 1)\n",
    "        seed = text[start_idx:start_idx + max_len]\n",
    "\n",
    "    sentence = seed\n",
    "    generated = sentence\n",
    "\n",
    "    while predict_more(generated):\n",
    "        # generate the input tensor\n",
    "        # from the last max_len characters generated so far\n",
    "        x = np.zeros((1, max_len, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_labels[char]] = 1.\n",
    "\n",
    "        # this produces a probability distribution over characters\n",
    "        probs = model.predict(x, verbose=0)[0]\n",
    "\n",
    "        # sample the character to use based on the predicted probabilities\n",
    "        next_idx = sample(probs, temperature)\n",
    "        next_char = labels_char[next_idx]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to draw samples from a Boltzmann distribution\n",
    "def sample(probs, temperature):\n",
    "    \"\"\"samples an index from a vector of probabilities\n",
    "    (this is not the most efficient way but is more robust)\"\"\"\n",
    "    a = np.log(probs)/temperature\n",
    "    dist = np.exp(a)/np.sum(np.exp(a))\n",
    "    choices = range(len(probs))\n",
    "    return np.random.choice(choices, p=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up models and text files\n",
    "model_file_json = \"direction_text_gen_model.json\"\n",
    "model_file_param = \"direction_text_gen_model_params_50.h5\"\n",
    "text_files = glob('../data/directions.txt')\n",
    "text_files[0:5]\n",
    "text = '\\n'.join([open(f, 'r').read() for f in text_files])\n",
    "text[0:500]\n",
    "chars = list(set(text))\n",
    "max_len = 20\n",
    "char_labels = {ch:i for i, ch in enumerate(chars)}\n",
    "labels_char = {i:ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: direction_text_gen_model.json direction_text_gen_model_params_50.h5 from disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open(model_file_json, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "fname = model_file_param\n",
    "model.load_weights(fname)\n",
    "print(\"Loaded model: \" + model_file_json + \" \" + model_file_param + \" from disk\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/ipykernel/__main__.py:5: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ing. Center 8 inch consectioners sugar, coffee, 1/4 cup cocoa, and white sugar. Blend in the water and stir until well blended. Add eggs one at a time, beating well after each addition. Set aside. In a medium bowl, combine flour, sugar, baking powder, salt, and spices. In an ext heat until thick. Repeat ut the batter. Bake in a preheated 350 degrees F (175 degrees C) for 30 to 35 minutes or until cake tests done. Cool. \r\n",
      "Preheat oven to 350 degrees F (175 degrees C) for 30 to 35 minutes. To Make Cool oven top the freezed for 2 hours. Combine with the white sugar and beat until stiff peaks form. Fold 1/3 of the whites into the batter alternately with milk in the bottom of a 9x13 inch pan. In a mixing bowl; stir in a medium lightly flour a bowl. Beat egg whites until stiff. Cover and place in a greased loaf pan. Let rise until doubled in a stiff, and stir. Pour batter into one 9 x 13 inch pan. Bake at 350 degrees F (175 degrees C). Grease and flour two 9 inch round cake pans. Prepare an \n"
     ]
    }
   ],
   "source": [
    "print('%s' % generate(temperature=0.55, seed='This cake recipe delicious a creamy cake that is easy to make.', num_chars=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
